model: "llama3:8b"
temperature: 0.2
max_tokens: 2048
log_level: "INFO"
